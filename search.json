[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "myblog",
    "section": "",
    "text": "Lewis Carroll - Final Project Blog\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nJul 31, 2023\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nJul 28, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/Topics.html",
    "href": "posts/Topics.html",
    "title": "Lewis Carroll - Final Project Blog",
    "section": "",
    "text": "This project is a NLP project on CORGIS CSV Datasets’ Classics csv file extracted from Project Gutenberg (PG). Classics csv is a collection of the top 1000 most popular books and their metadata on PG, as determined by downloads. I perform NLP techniques particularly on Lewis Carroll’s works and compare them with other books in PG to research his writing style and discover other insights.\n\n\n\nWhat’s Lewis Carroll’s writing style and what qualities make him unique?\n\n\n\nLewis Carroll,the author of Alice’s Adventures in Wonderland and its sequel Through the Looking-Glass, is one of the most well-known children’s fantasy writers from the 19th century. He’s also known by his real name Charles Lutwidge Dodgson, a brilliant mathematician and logician that invented the famous word ladder puzzle and had many significant contributions to the development of Mathematical Logic and Linear Algebra. While we’re astonished by Lewis’ outstanding achievements in both mathematics and literature, we may also want to explore the secret behind his talents–what he thinks about, how he reasons and the way he expresses. Apparently, the most direct key to access such secrets is his books.\nBy reading his book, we’re able to explore the inner world of this great mind and absorb intellectual nutrition from his creations. However, such endeavors could be fairly time-consuming and almost an unbearable burden for nowadays busy people. We then wonder: rather than dig deeply into the depth of Lewis’ writings, is there a more direct way to extract insights of his works or writing style through some analytic efforts? Fortunately, today we have many advanced techniques allowing us to perform such tasks and Natural Language Processing(NLP) is one of the most well-known methods in this field.In this project, I will perform various data analysis techniques, including NLP, on Lewis Carroll’s available works on Gutenberg.org and extract some insights from the analyses attemptedly, through which we can hopefully understand Lewis Carroll’s writing style better.\n\n\n\nAssignment 5–NLP, Assignment 4–web scraping and the other relevant python practices.\n\n\n\n\n\n\n\n# Importing classis.csv file. It's avaible on CORGIS for download and in this github repo.\nimport pandas as pd\n\nfile_path = 'classics.csv'\n\n# Read the CSV file into a pandas DataFrame\ndf = pd.read_csv(file_path)\n\n# Check if the file is loaded sucessfully\ndf.head()\n\n\n\n\n\n\n\n\nbibliography.congress classifications\nbibliography.languages\nbibliography.subjects\nbibliography.title\nbibliography.type\nmetadata.downloads\nmetadata.id\nmetadata.rank\nmetadata.url\nbibliography.author.birth\n...\nmetrics.sentiments.polarity\nmetrics.sentiments.subjectivity\nmetrics.statistics.average letter per word\nmetrics.statistics.average sentence length\nmetrics.statistics.average sentence per word\nmetrics.statistics.characters\nmetrics.statistics.polysyllables\nmetrics.statistics.sentences\nmetrics.statistics.syllables\nmetrics.statistics.words\n\n\n\n\n0\nPR\nen\nSisters -- Fiction,Courtship -- Fiction,Social...\nPride and Prejudice\nText\n36576\n1342\n1\nhttps://www.gutenberg.org/ebooks/1342\n1775\n...\n0.136713\n0.522239\n4.83\n18.0\n0.05\n586794\n4603\n6511\n170648.1\n121533\n\n\n1\nPS\nen\nMentally ill women -- Fiction,Feminist fiction...\nThe Yellow Wallpaper\nText\n26363\n1952\n2\nhttps://www.gutenberg.org/ebooks/1952\n1860\n...\n0.054174\n0.534787\n4.41\n15.0\n0.06\n26769\n102\n385\n7686.9\n6067\n\n\n2\nPZ,PR\nen\nFantasy\nAlice's Adventures in Wonderland\nText\n18882\n11\n3\nhttps://www.gutenberg.org/ebooks/11\n1832\n...\n0.041079\n0.497276\n4.65\n17.0\n0.06\n122719\n339\n1501\n33810.3\n26389\n\n\n3\nPR\nen\nMonsters -- Fiction;Frankenstein's monster (Fi...\nFrankenstein; Or, The Modern Prometheus\nText\n17128\n84\n4\nhttps://www.gutenberg.org/ebooks/84\n1797\n...\n0.100902\n0.539516\n4.77\n23.0\n0.04\n357604\n2604\n3239\n106802.1\n74959\n\n\n4\nPT\nen\nPsychological fiction,Metamorphosis -- Fiction\nMetamorphosis\nText\n15683\n5200\n5\nhttps://www.gutenberg.org/ebooks/5200\n1883\n...\n0.041997\n0.479019\n4.56\n27.0\n0.04\n100372\n397\n800\n28752.3\n22022\n\n\n\n\n5 rows × 38 columns\n\n\n\n\n# Checking Missing data\nmissing_data = df.isnull().sum()\n\nprint(missing_data)\n\nbibliography.congress classifications              159\nbibliography.languages                               0\nbibliography.subjects                              155\nbibliography.title                                   0\nbibliography.type                                    0\nmetadata.downloads                                   0\nmetadata.id                                          0\nmetadata.rank                                        0\nmetadata.url                                         0\nbibliography.author.birth                            0\nbibliography.author.death                            0\nbibliography.author.name                             0\nbibliography.publication.day                         0\nbibliography.publication.full                        0\nbibliography.publication.month                       0\nbibliography.publication.month name                  0\nbibliography.publication.year                        0\nmetadata.formats.total                               0\nmetadata.formats.types                               0\nmetrics.difficulty.automated readability index       0\nmetrics.difficulty.coleman liau index                0\nmetrics.difficulty.dale chall readability score      0\nmetrics.difficulty.difficult words                   0\nmetrics.difficulty.flesch kincaid grade              0\nmetrics.difficulty.flesch reading ease               0\nmetrics.difficulty.gunning fog                       0\nmetrics.difficulty.linsear write formula             0\nmetrics.difficulty.smog index                        0\nmetrics.sentiments.polarity                          0\nmetrics.sentiments.subjectivity                      0\nmetrics.statistics.average letter per word           0\nmetrics.statistics.average sentence length           0\nmetrics.statistics.average sentence per word         0\nmetrics.statistics.characters                        0\nmetrics.statistics.polysyllables                     0\nmetrics.statistics.sentences                         0\nmetrics.statistics.syllables                         0\nmetrics.statistics.words                             0\ndtype: int64\n\n\nWe observe 159 missing data in “bibliography.congress classifications” column and 155 in “bibliography.subjects” column. Since both variables are not the primary focus of this research, we don’t need to further investigate these missing data.  We also wonder how many authors are in this dataset?\n\nprint(\"There are\", len(df[\"bibliography.author.name\"].unique()), \"authors in classics.csv dataset.\")\n\nThere are 555 authors in classics.csv dataset.\n\n\n\n\n\n\n\n\n\n\n\nbibliography.congress classifications\nbibliography.languages\nbibliography.subjects\nbibliography.title\nbibliography.type\nmetadata.downloads\nmetadata.id\nmetadata.rank\nmetadata.url\nbibliography.author.birth\n...\nmetrics.sentiments.polarity\nmetrics.sentiments.subjectivity\nmetrics.statistics.average letter per word\nmetrics.statistics.average sentence length\nmetrics.statistics.average sentence per word\nmetrics.statistics.characters\nmetrics.statistics.polysyllables\nmetrics.statistics.sentences\nmetrics.statistics.syllables\nmetrics.statistics.words\n\n\n\n\n2\nPZ,PR\nen\nFantasy\nAlice's Adventures in Wonderland\nText\n18882\n11\n3\nhttps://www.gutenberg.org/ebooks/11\n1832\n...\n0.041079\n0.497276\n4.65\n17.0\n0.06\n122719\n339\n1501\n33810.3\n26389\n\n\n67\nPR,PZ\nen\nFantasy\nThrough the Looking-Glass\nText\n3626\n12\n68\nhttps://www.gutenberg.org/ebooks/12\n1832\n...\n0.087243\n0.486645\n4.71\n15.0\n0.07\n137377\n373\n1938\n37274.4\n29170\n\n\n183\nPZ,PR\nen\nFantasy\nAlice's Adventures in Wonderland\nText\n1660\n19033\n184\nhttps://www.gutenberg.org/ebooks/19033\n1832\n...\n0.030640\n0.470152\n4.66\n16.0\n0.06\n45325\n139\n592\n12559.5\n9721\n\n\n275\nPZ,PR\nen\nFantasy\nAlice's Adventures in Wonderland: Illustrated ...\nText\n1229\n28885\n276\nhttps://www.gutenberg.org/ebooks/28885\n1832\n...\n0.036749\n0.498011\n4.71\n17.0\n0.06\n128331\n384\n1551\n35064.9\n27270\n\n\n654\nPR,PZ\nde\nFantasy\nAlice's Abenteuer im Wunderland\nText\n599\n19778\n655\nhttps://www.gutenberg.org/ebooks/19778\n1832\n...\n0.414417\n0.538158\n5.39\n15.0\n0.06\n137490\n459\n1637\n34974.9\n25515\n\n\n733\nBC\nen\nLogic -- Juvenile literature;Logic, Symbolic a...\nThe Game of Logic\nText\n544\n4763\n734\nhttps://www.gutenberg.org/ebooks/4763\n1832\n...\n0.072815\n0.494916\n5.48\n13.0\n0.08\n78980\n430\n1088\n18483.3\n14408\n\n\n790\nBC\nen\nLogic, Symbolic and mathematical\nSymbolic Logic\nText\n510\n28696\n791\nhttps://www.gutenberg.org/ebooks/28696\n1832\n...\n0.076662\n0.466312\n5.59\n13.0\n0.07\n313684\n2063\n4045\n69408.0\n56160\n\n\n\n\n7 rows × 38 columns\n\n\n\nWe manually examine Lewis Caroll related dataframe since it only has 7 rows/items and there’s no missing values in this dataframe. We also notice there’s 4 versions of Alice’s Adventure in Wonderland and one of them is in Germany. To avoid repetitive analysis on the same book, here we only select “https://www.gutenberg.org/ebooks/11 Alice’s Adventure in Wonderland with the higest download. Subsetting this dataframe to the no-repeat (np) dataframe we need for our detail analysis:\n\ndf_CL_np = df_CL.iloc[[0,1, 5, 6]]\ndf_CL_np\n\n\n\n\n\n\n\n\nbibliography.congress classifications\nbibliography.languages\nbibliography.subjects\nbibliography.title\nbibliography.type\nmetadata.downloads\nmetadata.id\nmetadata.rank\nmetadata.url\nbibliography.author.birth\n...\nmetrics.sentiments.polarity\nmetrics.sentiments.subjectivity\nmetrics.statistics.average letter per word\nmetrics.statistics.average sentence length\nmetrics.statistics.average sentence per word\nmetrics.statistics.characters\nmetrics.statistics.polysyllables\nmetrics.statistics.sentences\nmetrics.statistics.syllables\nmetrics.statistics.words\n\n\n\n\n2\nPZ,PR\nen\nFantasy\nAlice's Adventures in Wonderland\nText\n18882\n11\n3\nhttps://www.gutenberg.org/ebooks/11\n1832\n...\n0.041079\n0.497276\n4.65\n17.0\n0.06\n122719\n339\n1501\n33810.3\n26389\n\n\n67\nPR,PZ\nen\nFantasy\nThrough the Looking-Glass\nText\n3626\n12\n68\nhttps://www.gutenberg.org/ebooks/12\n1832\n...\n0.087243\n0.486645\n4.71\n15.0\n0.07\n137377\n373\n1938\n37274.4\n29170\n\n\n733\nBC\nen\nLogic -- Juvenile literature;Logic, Symbolic a...\nThe Game of Logic\nText\n544\n4763\n734\nhttps://www.gutenberg.org/ebooks/4763\n1832\n...\n0.072815\n0.494916\n5.48\n13.0\n0.08\n78980\n430\n1088\n18483.3\n14408\n\n\n790\nBC\nen\nLogic, Symbolic and mathematical\nSymbolic Logic\nText\n510\n28696\n791\nhttps://www.gutenberg.org/ebooks/28696\n1832\n...\n0.076662\n0.466312\n5.59\n13.0\n0.07\n313684\n2063\n4045\n69408.0\n56160\n\n\n\n\n4 rows × 38 columns\n\n\n\nEach “Plain Text UTF-8” file is stored in its corresponding metadata.url with addtional suffix “/pg{metadata.id}.txt”. With this feature we can extract the plain text of these four books by their “metadata.url”. Append this to the above dataframe:\n\nmetadata_ids = df_CL_np[\"metadata.id\"]\nplaintext_urls = []\n\n# Build the plaintext URLs for each book using the metadata.ids\nfor metadata_id in metadata_ids:\n    plaintext_url = f\"https://www.gutenberg.org/cache/epub/{metadata_id}/pg{metadata_id}.txt\"\n    plaintext_urls.append(plaintext_url)\n    \n\n\n# load the text file into objects named by the book title:\nimport requests\n\nplaintext_urls\ntitles = df_CL_np[\"bibliography.title\"].tolist()\nbook_texts = {}\n \nfor title, url in zip(titles, plaintext_urls):\n    response = requests.get(url)\n    plain_text = response.text\n    book_texts[title] = plain_text\n\nalice = book_texts[\"Alice's Adventures in Wonderland\"]\nglass = book_texts[\"Through the Looking-Glass\"]\ngame = book_texts[\"The Game of Logic\"]\nsymbolic = book_texts[\"Symbolic Logic\"] \n\n\n\nWord Count for Alice: 29564\nWord Count for Glass: 32784\nWord Count for Game: 20504\nWord Count for Symbolic: 69243\n\n\nBy checking the word count for each book and comparing them to the word count in the df_CL_np dataframe, we know our texts are loaded successfully into these objects. These word counts are higher than ones in the df_CL_np dataframe; we haven’t precisely tokenized them by words.\n\n\n\nMy Analytical Process will be divided into two parts: first, the comparison between Lewis Caroll to the others in the big classics dataset; second, a detail investigation of the features of our selected books from Lewis Carroll.\nIn the first part, I will perform such comparisons by visualizing my selected variables for the classics dataset and highlighting the same variables in Lewis Carroll’s dataframe in their corresponding positions. Visualizations for this part will include histograms with highlighted lines, a scatter-plot with regression line and highlighted points.\n\n\n\n\n\n\n\n\nNow we move on to fit Lewis Caroll into the “big picture” of the large “classics.csv” dataset and compare him with the others through data analysis. In this process we will also conduct some exploratory data analysis just to learn more about the classic.csv dataset.\nGiven the popularity of Alice’s Adventure in Wonderland , Lewis Caroll is undoubtedly a well-known writer in the field of classical literature. But how popular is he compared to the other authors, measured by the number of available books in the GP project? With the following codes we will performe this analysis.\n\n\ncount    555.000000\nmean       1.812613\nstd        2.447467\nmin        1.000000\n25%        1.000000\n50%        1.000000\n75%        2.000000\nmax       34.000000\nName: bibliography.author.name, dtype: float64\nUnknown                    34\nShakespeare, William       19\nTwain, Mark                19\nDickens, Charles           18\nDoyle, Arthur Conan        14\n                           ..\nHerodotus                   1\nBurke, Edmund               1\nMachen, Arthur              1\nBoy Scouts of America       1\nMorse, Katharine Duncan     1\nName: bibliography.author.name, Length: 555, dtype: int64\n\n\n\n\nLewis Carroll's Rank: 17.0\n\n\n\n# Visualization1: Visualize Lewis Carroll's rank in the top 50 authors.\nimport matplotlib.pyplot as plt\n\n# Create a bar plot for the top 50 authors, including Lewis Carroll\ntop_authors = author_counts.head(50)\n\n# Sort the top authors Series by count in descending order\ntop_authors = top_authors.sort_values(ascending=False)\n\n# Create the bar plot\nplt.figure(figsize=(12, 6))  # Optional: Adjust the size of the plot\nax = top_authors.plot(kind='bar', color='skyblue')\n\n# Highlight Lewis Carroll's bar with a different color (e.g., red)\nlewis_carroll_index = top_authors.index.get_loc(\"Carroll, Lewis\")\nax.patches[lewis_carroll_index].set_facecolor('red')\n\n# Add labels and title\nplt.xlabel('Author')\nplt.ylabel('Number of Books')\nplt.title('V1.Number of Books per Author (Top 50)')\n\n# Display the plot\nplt.show()\n\n\n\n\nSince there are over 500 authors in the GP project and over 50% of them only have 1 book collected in the project, if we plot all of their book counts we expect to see a highly right-skewed, less insightful graph. Therefore, it’s better to tailor the graph to the top 50 writers and compare Lewis (rank 17) with the others.\nIn “Number of Books per Author (Top 50)”, Lewis is highlighted by the red color. Authors before him are also well-known writers like “Mark Twain,”Shakespeare”, “Oscar Wilde”, “Jane Austen” and etc.We should notice the genre of their works can be quite different: for example, “Mark Twain” like to write short novels and “Shakespear” writes lots of poems and dramas; these, given their short length, may increase their authors’ book count. We also notice many books fall into names of “Unknown” and “Anonymous”, which should be ignored from this graph since they’re not correctly defined. After these modifications, we can conclude Lewis Carroll is a very popular writer even among the top 50 writers in the GP project.\n\n\n\n\nNext, we want to perform an analysis on the sentiment analysis scores of Lewis and the others and research the relationship between sentiment subjectivity and sentiment polarity.We also want to know where Lewis sits in the big picture of the GPD project sentiment scores.\n\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\nx = df[\"metrics.sentiments.subjectivity\"]\ny = df[\"metrics.sentiments.polarity\"]\n\nx_lewis = df_CL_np[\"metrics.sentiments.subjectivity\"]\ny_lewis = df_CL_np[\"metrics.sentiments.polarity\"]\n\n# Create a scatter plot for the others\nplt.scatter(x, y, label = \"others\")\n# Create a scatter plot for lewis\nplt.scatter(x_lewis, y_lewis, label = \"Lewis\")\n\n# Add labels and title\nplt.xlabel('Subjectivity')\nplt.ylabel('Polarity')\nplt.title('V2. Correlation between Subjectivity and Polarity ')\n\n# fit regression for the others\nlm = LinearRegression()\nx = np.array(x).reshape(-1, 1)\ny = np.array(y).reshape(-1, 1)\nlm.fit(x,y )\n# Get the coefficients of the linear model for the others\nslope = lm.coef_[0]\nintercept = lm.intercept_\nplt.plot(x, slope * x + intercept, color='red', label='Regression Line')\n\n\n# Show the plot\nplt.show()\n\nprint(\"The slope of this graph is \",slope)\n\n\n\n\nThe slope of this graph is  [0.49959358]\n\n\nAs CORGIS database describes, “Subjectivity (as opposed to Objectivity) in particular refers to whether the text is opinionated or attempts to stay factual” and “Polarity in particular refers to how positive or negative the author is towards the content”. Through plotting them in the same scatter plot, we attempt to find if the more subjective an author is in his/her writing, the more positive will the overall attitude of the book be. \nIn this graph, we identify a positive relation between the sentiment subjectivity and sentiment polarity with a slope of 0.4995. We infer there’s a possibility that the more subjective an author is, the more positive this will be in his attitude towards his works.\nWe also view the majority of data points concentrated within the 0.4-06 subjectivity range for x-axis and the 0.0-0.2 polarity range for y-axis. Lewis Caroll locates in the center of this cluster, indicating he has an overall subjective tone and a positive choice of words in his writings.\n\n\n\n\nWhat about Lewis’ average sentence length compared to the other writers? Does he prefer to write in short or long sentences? This is also an important factor that influences one’s writing style. From our experience, we can tell that generally short sentences provide better readability while the long sentences require the reader to be more concentrated and skillful in reading. So does Lewis try to better engage his audience with shorter sentences or make his works more readible?\n\n\n2      17.0\n67     15.0\n733    13.0\n790    13.0\nName: metrics.statistics.average sentence length, dtype: float64\ncount    1006.000000\nmean       20.801193\nstd        10.740644\nmin         5.000000\n25%        15.000000\n50%        19.000000\n75%        24.000000\nmax       235.000000\nName: metrics.statistics.average sentence length, dtype: float64\n\n\nWe extract the average sentence length for four unique books in our Lewis Carroll dataframe. Then we add a five number description to the big classics dataframe on its average sentence length variable. We also visualize Lewis’ average sentence length together with the others’:\n\ndt_sentence_length = df['metrics.statistics.average sentence length']\ncl_sentence_length = df_CL_np[\"metrics.statistics.average sentence length\"]\n\nplt.hist(dt_sentence_length[dt_sentence_length &lt;40], bins = len(dt_sentence_length) ,edgecolor='black')\n\n# Add labels and title\nplt.xlabel('Average sentence length')\nplt.ylabel('Frequency')\nplt.title('V3: Average sentence length')\n\n# Display the histogram\nfor length in cl_sentence_length:\n    plt.axvline(length, color='red', linestyle='dashed', linewidth=1, label=f'Length = {length}')\n\n# Display the histogram\nplt.legend()\nplt.show()\n\n\n\n\nIn this graph, we observe 16 words/sentences is the most popular length for authors in the GP project. The graph is relatively right-skewed, meaning most writers prefer short-medium average sentence length in the first to the third quantile. Lewis’ books have shorter average sentences length than the average (mean = 20.801), all falling in between 0% to 50%. This might indicate Lewis prefers to write shorter sentence structure to engage his reader better.\n\n\n\n\nTo confirm our findings in our 3rd visualization, in the final step of our data analysis of comparing Lewis to the entire Classics dataframe, we will visualize the “metrics.difficulty.automated readability index” for all the books in GP project and highlight Lewis Caroll’s readability indexs with red color.\n\ndata = df[\"metrics.difficulty.automated readability index\"]\ndata_lewis = df_CL_np[\"metrics.difficulty.automated readability index\"]\n\n# Create a figure with two subplots\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n\n# Plot the histogram of the unfiltered data in the first subplot\nax1.hist(data, bins=len(data.unique()), edgecolor='black')\nax1.set_xlabel('Value')\nax1.set_ylabel('Frequency')\nax1.set_title('Histogram (All Data)')\n\n# Filter the data between 0 and 100\ndata_filtered = data[(data &gt;= 0) & (data &lt;= 40)]\n\n# Plot the histogram of the filtered data in the second subplot\nax2.hist(data_filtered, bins=len(data_filtered.unique()), edgecolor='blue')\nax2.set_xlabel('Value')\nax2.set_ylabel('Frequency')\nax2.set_title('V4.Histogram (Data between 0 and 40)')\n\n# Plot Lewis Carroll's data on the second subplot\nax2.hist(data_lewis, bins=len(data_lewis.unique()), color='red', alpha=0.6, edgecolor='black')\nax2.legend(['All Data',  'Lewis Carroll'])\n\n# Adjust layout to avoid overlapping labels\nplt.tight_layout()\n\n# Display the histograms\nplt.show()\n\nprint (\"readability index of Lewis Carroll \",data_lewis)\n\n\n\n\nreadability index of Lewis Carroll  2       9.3\n67      8.3\n733    11.0\n790    11.8\nName: metrics.difficulty.automated readability index, dtype: float64\n\n\nSince we observe the untailored plot has an outlier (&gt;120) that stretches the whole graph to the right and reduces the interpretability of our visualization, we decide to tailor the data between 0 and 40 since the vast majority of data fall into this range. \nBased on CORGIS database’ description, “The Automated Readability Index is a number indicating the understandability of the text. This number is an approximate US Grade Level needed to comprehend the text, calculated using the characters per word and words per sentences.” For example, if a book has 11 as its readability index, this means it’s readable for an 11th grader. \nAs said, we also highlight Lewis’ readability score in the second (the better) graph, by which we can see his readability indexes land on the lower side, which indicates his works are readable for young readers in middle/high school (7th grade- 12 grade).\n\n\n\n\n\n\n  To further process our data, we download necessary packages like nltk, matplotlib, requests. \n\n\nimport requests\nimport matplotlib.pyplot as plt\nimport nltk\n\nfrom nltk.tokenize import word_tokenize\nfrom nltk.sentiment import vader\nfrom nltk.corpus import stopwords\nfrom nltk.corpus import opinion_lexicon\nfrom nltk.stem.porter import PorterStemmer\n\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('vader_lexicon')\nnltk.download('opinion_lexicon')\n\n[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /home/jovyan/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n[nltk_data] Downloading package opinion_lexicon to\n[nltk_data]     /home/jovyan/nltk_data...\n[nltk_data]   Package opinion_lexicon is already up-to-date!\n\n\nTrue\n\n\nWe then extract the contents for our four selected books. We also import english stops as a python list from nltk.corpus package and analyzer from vader package for later use. Once we obtain string objects for each book, we tokenize each of them and remove stop words from them.\n\n\n\nAfter completing the above data processing steps, we are ready to create word clouds for each book. Through these word clouds, we can grasp the most frequently appeared words in each book and potentially their themes or subjects.\n\nfrom wordcloud import WordCloud\n\n# Assuming 'alice_words', 'glass_words', 'game_words', and 'symbolic_words' are the tokenized word lists.\n\ndef generate_word_cloud(book_title, word_list):\n    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(word_list))\n    plt.figure(figsize=(10, 5))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.title(f'Word Cloud for {book_title}')\n    plt.show()\n\n# Generate word clouds for each book\ngenerate_word_cloud(\"Alice's Adventures in Wonderland\", alice_words_nr)\ngenerate_word_cloud(\"Through the Looking-Glass\", glass_words_nr)\ngenerate_word_cloud(\"The Game of Logic\", game_words_nr)\ngenerate_word_cloud(\"Symbolic Logic\", symbolic_words_nr)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs we look through the word clouds for each graph, we do realize they are different by their subjects. The first two word clouds look similar with many identical words like “alice”, “thing”, “rabbit”, “door” because both books– Alice’s Adventure in Wonderland and Through the Looking-Glass–are storybook about the same protagonist Alice’s adventures.\nThe later two books all fall into the “Logic” subject. Therefore, we can see many similar terms about logic frequently appear in these two books, such as “x”, “syllogism”, “conclusion”, “proposition” and etc.\n\n\n\nAlthough word clouds reflect the most frequently appeared words in these books and disclose their themes to an extent, this technique still has its own limits, such as being too generalized and unable to describe the mood behind the words.\nTo complement the limits of a NLP technique, we usually use other NLP techniques to cover the areas it doesn’t explain. In my case, I’ll use sentiment analysis of positive and negative words to more precisely reflect Lewis Carroll’s writing style in Fantasy and Logic topics.\n\n#----------------------\n# Create horizontal bar plots\nplt.figure(figsize=(10, 6))\n# Plot for negative words\nplt.subplot(2, 2, 1)\nplt.barh(range(len(top_15_alice_ns_negative_words[::-1])), [count for word, count in top_15_alice_ns_negative_words[::-1]], align='center',color='purple')\nplt.yticks(range(len(top_15_alice_ns_negative_words[::-1])), [word for word, count in top_15_alice_ns_negative_words[::-1]])\nplt.xlabel('Frequency')\nplt.title('15 Most Common Negative Words in Alice')\n\n# Plot for positive words\nplt.subplot(2, 2, 2)\nplt.barh(range(len(top_15_alice_ns_positive_words[::-1])), [count for word, count in top_15_alice_ns_positive_words[::-1]], align='center',color='orange')\nplt.yticks(range(len(top_15_alice_ns_positive_words[::-1])), [word for word, count in top_15_alice_ns_positive_words[::-1]])\nplt.xlabel('Frequency')\nplt.title('15 Most Common Positive Words in Alice')\n\n# Plot for negative words\nplt.subplot(2, 2, 3)\nplt.barh(range(len(top_15_glass_ns_negative_words[::-1])), [count for word, count in top_15_glass_ns_negative_words[::-1]], align='center',color='purple')\nplt.yticks(range(len(top_15_glass_ns_negative_words[::-1])), [word for word, count in top_15_glass_ns_negative_words[::-1]])\nplt.xlabel('Frequency')\nplt.title('15 Most Common Negative Words in glass')\n\n# Plot for positive words\nplt.subplot(2, 2, 4)\nplt.barh(range(len(top_15_glass_ns_positive_words[::-1])), [count for word, count in top_15_glass_ns_positive_words[::-1]], align='center',color='orange')\nplt.yticks(range(len(top_15_glass_ns_positive_words[::-1])), [word for word, count in top_15_glass_ns_positive_words[::-1]])\nplt.xlabel('Frequency')\nplt.title('15 Most Common Positive Words in glass')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nAs we compare the 15 most frequently used positive words in Lewis’ two fantasy books Alie’s Adventure in Wonderland and Through the Looking-Glass, we find Lewis’ uses of positive words in his fantasy writing are very similar and have many overlaps across books. Words such as “like”, “well”, “great”,“good”, “wish” all ranked high in these lists.\nLooking into the 15 most frequently used negative words, we find although there are some overlapping words like “lying” and “poor”, the overall feeling is way more different than the homogeneousness we sense from the positive word lists. Based on this we can infer Lewis may set different challenges for Alice across two books with different use of negative words.\n \n\n\n\n#----------------------\n# Create horizontal bar plots\nplt.figure(figsize=(10, 6))\n\n# Plot for negative words\nplt.subplot(2, 2, 1)\nplt.barh(range(len(top_15_symbolic_ns_negative_words[::-1])), [count for word, count in top_15_symbolic_ns_negative_words[::-1]], align='center',color='purple')\nplt.yticks(range(len(top_15_symbolic_ns_negative_words[::-1])), [word for word, count in top_15_symbolic_ns_negative_words[::-1]])\nplt.xlabel('Frequency')\nplt.title('15 Most Common Negative Words in symbolic')\n\n# Plot for positive words\nplt.subplot(2, 2, 2)\nplt.barh(range(len(top_15_symbolic_ns_positive_words[::-1])), [count for word, count in top_15_symbolic_ns_positive_words[::-1]], align='center',color='orange')\nplt.yticks(range(len(top_15_symbolic_ns_positive_words[::-1])), [word for word, count in top_15_symbolic_ns_positive_words[::-1]])\nplt.xlabel('Frequency')\nplt.title('15 Most Common Positive Words in symbolic')\n\n# Plot for negative words\nplt.subplot(2, 2, 3)\nplt.barh(range(len(top_15_game_ns_negative_words[::-1])), [count for word, count in top_15_game_ns_negative_words[::-1]], align='center',color='purple')\nplt.yticks(range(len(top_15_game_ns_negative_words[::-1])), [word for word, count in top_15_game_ns_negative_words[::-1]])\nplt.xlabel('Frequency')\nplt.title('15 Most Common Negative Words in game')\n\n# Plot for positive words\nplt.subplot(2, 2, 4)\nplt.barh(range(len(top_15_game_ns_positive_words[::-1])), [count for word, count in top_15_game_ns_positive_words[::-1]], align='center',color='orange')\nplt.yticks(range(len(top_15_game_ns_positive_words[::-1])), [word for word, count in top_15_game_ns_positive_words[::-1]])\nplt.xlabel('Frequency')\nplt.title('15 Most Common Positive Words in game')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nRegarding Lewis Logic book writing, we found similar patterns exist in his fantasy books. Lewis prefers to use positive words from the same group to express an uplifting tone, while he uses different negative words to accurately describe different qualities or negations.\n\n\n\n\n# Split Alice's Adventure in Wonderland by chapters.\nimport re\n# Define the regular expression pattern to match chapter headings\nalice_chapter_pattern = r\"\\bCHAPTER\\b\"\n\n# Split the text into chapters based on the pattern\nalice_chapters = re.split(alice_chapter_pattern, alice, flags=re.IGNORECASE)\n\n# remove the first 1 (content before table of content)+12 (table of content)\nalice_chapters = alice_chapters[13:]\n\n# Initialize lists to store chapter numbers and sentiment scores\nalice_chapter_numbers = []\nalice_sentiment_scores = []\n\n# Iterate over the chapters in Alice's Adventures in Wonderland\nfor i, chapter_text in enumerate(alice_chapters, 1):\n    # Tokenize the chapter's text into words\n    words = nltk.word_tokenize(chapter_text)\n    \n    # Calculate the total chapter sentiment score by summing the compound scores of all the words in that chapter\n    chapter_score = sum(analyzer.polarity_scores(word)[\"compound\"] for word in words)\n    \n    # Append chapter number and sentiment score to the respective lists\n    alice_chapter_numbers.append(i)\n    alice_sentiment_scores.append(chapter_score)\n\n\n\n12\n12\n\n\n\n\n12\n12\n\n\n\n\n4\n4\n\n\n\n\n62\n62\n\n\n\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\n\n\n[9.590500000000002, 6.304400000000002, 9.064600000000008, 13.2118, 3.5087000000000024, 5.3100000000000005, 4.941000000000002, 6.0459, -3.1251999999999955, 10.476700000000001, 2.5824000000000016, 2.535399999999999, 12.669600000000008, 17.681499999999996, 20.522800000000004, 13.699000000000021, 23.6025, 32.70139999999999, 12.393300000000007, 24.61990000000001, 11.689600000000004, -0.5766, 0.0, 9.765900000000004, 10.095300000000112, -10.526699999999993, -18.835899999999967, 8.473900000000004, 0.0, -0.1531, -3.0889, 1.2140000000000002, 6.385199999999999, 0.0, 0.0, 0.0, 0.0, 0.0, -0.296, 0.0, -0.296, 0.2732, 0.0516, -2.9827999999999997, 0.0, 0.0, -0.8879999999999999, 0.0516, 0.0, 0.0, -0.4019, 0.0, -0.8879999999999999, 0.9981, -0.3818, -0.0837, 0.0, 0.0, 0.5337000000000001, -0.296, 2.0790000000000006, 1.7135, 1.3765999999999998, 2.9975, 1.3971, 2.4674000000000014, 5.6193, 0.5464, 0.4012, 4.4626, 0.0, 2.2735000000000003, -23.96019999999997, -0.12869999999999998, -0.5753999999999997, 0.2732, 1.9924, -8.778200000000002, -8.433900000000001, -0.6636999999999997, 1.4478, 9.459699999999994, -0.546, -4.054899999999999, 19.71710000000001, 0.6137999999999998, 3.609600000000003, -35.16309999999992, -24.156999999999957, 72.5355]\n\n\n\n# Set colors for positive, negative, and neutral scores\n\ncolors = ['purple' if score &lt; 0 else 'orange' if score &gt; 0 else 'blue' for score in combined_list]\nbar_width = 0.5\n\n# Create a 2x2 grid of subplots\nfig, axes = plt.subplots(2, 2, figsize=(15, 10))\n\n# Plot the first subplot for \"Alice's Adventure in Wonderland\"\naxes[0, 0].bar(alice_chapter_numbers, alice_sentiment_scores, color=colors, width=bar_width)\naxes[0, 0].set_xlabel(\"Scene Number\")\naxes[0, 0].set_ylabel(\"Sentiment Score\")\naxes[0, 0].set_title(\"Alice's Adventure in Wonderland\")\n\n# Plot the second subplot for \"Through the Looking Glass\"\naxes[0, 1].bar(glass_chapter_numbers, glass_sentiment_scores, color=colors, width=bar_width)\naxes[0, 1].set_xlabel(\"Scene Number\")\naxes[0, 1].set_ylabel(\"Sentiment Score\")\naxes[0, 1].set_title(\"Through the Looking Glass\")\n\n# Plot the third subplot for \"game\"\naxes[1, 0].bar(game_chapter_numbers, game_sentiment_scores, color=colors, width=bar_width)\naxes[1, 0].set_xlabel(\"Scene Number\")\naxes[1, 0].set_ylabel(\"Sentiment Score\")\naxes[1, 0].set_title(\"game\")\n\n# Plot the fourth subplot for \"symbolic\"\naxes[1, 1].bar(symbolic_chapter_numbers, symbolic_sentiment_scores, color=colors, width=bar_width)\naxes[1, 1].set_xlabel(\"Scene Number\")\naxes[1, 1].set_ylabel(\"Sentiment Score\")\naxes[1, 1].set_title(\"symbolic\")\n\n# Adjust layout and display the plots\nplt.tight_layout()\nplt.show()\n\n\n\n\nAs we visualize the polarity scores of Lewis’ four books, we identify he always hold a positive tone in his fantasy books but write more objectively (close to 0 score) or uses strong negations in his logic books. My assumption is in the logic book, since negations or counter examples are freuqently use as parts of the proof, it results an overall lower sentiment score for this type of books.\n\n\n\n\n\nwhat does your analysis show, what is the big picture, and how are these findings useful?\nBased on the above analysis, I’m able to conclude some uniqueness of Lewis Caroll few features I discover his writing style: 1. Lewis Caroll is a very popular (ranked as 17th) writer over 555 writers collected in the GP project. 2. He tends to be subjective in his writing with an overall positive attitude. 3. He prefers to write in short sentences, lower than the overall average sentence length in the GP project. 4. His works are usually easy to read, even for the 7th-12th grader. 5. Given he’s both a Mathematician and a fantasy writer, to create engaging works in both fields for different types of readers, Lewis approaches his writings with different tones. For his fantasy writings, he tends to use many positive words and holds a constant positive tone throughout the books. But for his logic books, he tends to be more critical and objective by using more negative or neutral words. 6. His choices of positive words are very similar across his fantasy books while the negative words are different to represent the varying adventure his protagonist–Alice–experiences. Similar patent is found in his logic writings: similar choices of positive words, different negative words to express varying negations and qualities.\nThese findings are useful for us to better understand Lewis Carroll’s writing style and are presentable for educational purposes. I think they will be very helpful literature teachers who want to incorporate Digital Humanity methods into his/her lecture and introduce Lewis Carroll from a computational angle. For Lewis’ reader, these findings are also useful as you can examine them in your reading of Lewis’ works and make comparisons. Although some of them are proved to be not true, in your process of validation–finding the right features about Lewis from the text–you still learn more than reading his texts passively. I think these are the benefits offered by my findings."
  },
  {
    "objectID": "posts/Topics.html#i.-introduction",
    "href": "posts/Topics.html#i.-introduction",
    "title": "Lewis Carroll - Final Project Blog",
    "section": "",
    "text": "This project is a NLP project on CORGIS CSV Datasets’ Classics csv file extracted from Project Gutenberg (PG). Classics csv is a collection of the top 1000 most popular books and their metadata on PG, as determined by downloads. I perform NLP techniques particularly on Lewis Carroll’s works and compare them with other books in PG to research his writing style and discover other insights.\n\n\n\nWhat’s Lewis Carroll’s writing style and what qualities make him unique?\n\n\n\nLewis Carroll,the author of Alice’s Adventures in Wonderland and its sequel Through the Looking-Glass, is one of the most well-known children’s fantasy writers from the 19th century. He’s also known by his real name Charles Lutwidge Dodgson, a brilliant mathematician and logician that invented the famous word ladder puzzle and had many significant contributions to the development of Mathematical Logic and Linear Algebra. While we’re astonished by Lewis’ outstanding achievements in both mathematics and literature, we may also want to explore the secret behind his talents–what he thinks about, how he reasons and the way he expresses. Apparently, the most direct key to access such secrets is his books.\nBy reading his book, we’re able to explore the inner world of this great mind and absorb intellectual nutrition from his creations. However, such endeavors could be fairly time-consuming and almost an unbearable burden for nowadays busy people. We then wonder: rather than dig deeply into the depth of Lewis’ writings, is there a more direct way to extract insights of his works or writing style through some analytic efforts? Fortunately, today we have many advanced techniques allowing us to perform such tasks and Natural Language Processing(NLP) is one of the most well-known methods in this field.In this project, I will perform various data analysis techniques, including NLP, on Lewis Carroll’s available works on Gutenberg.org and extract some insights from the analyses attemptedly, through which we can hopefully understand Lewis Carroll’s writing style better.\n\n\n\nAssignment 5–NLP, Assignment 4–web scraping and the other relevant python practices."
  },
  {
    "objectID": "posts/Topics.html#ii.-method-data-explanation-analytical-process",
    "href": "posts/Topics.html#ii.-method-data-explanation-analytical-process",
    "title": "Lewis Carroll - Final Project Blog",
    "section": "",
    "text": "# Importing classis.csv file. It's avaible on CORGIS for download and in this github repo.\nimport pandas as pd\n\nfile_path = 'classics.csv'\n\n# Read the CSV file into a pandas DataFrame\ndf = pd.read_csv(file_path)\n\n# Check if the file is loaded sucessfully\ndf.head()\n\n\n\n\n\n\n\n\nbibliography.congress classifications\nbibliography.languages\nbibliography.subjects\nbibliography.title\nbibliography.type\nmetadata.downloads\nmetadata.id\nmetadata.rank\nmetadata.url\nbibliography.author.birth\n...\nmetrics.sentiments.polarity\nmetrics.sentiments.subjectivity\nmetrics.statistics.average letter per word\nmetrics.statistics.average sentence length\nmetrics.statistics.average sentence per word\nmetrics.statistics.characters\nmetrics.statistics.polysyllables\nmetrics.statistics.sentences\nmetrics.statistics.syllables\nmetrics.statistics.words\n\n\n\n\n0\nPR\nen\nSisters -- Fiction,Courtship -- Fiction,Social...\nPride and Prejudice\nText\n36576\n1342\n1\nhttps://www.gutenberg.org/ebooks/1342\n1775\n...\n0.136713\n0.522239\n4.83\n18.0\n0.05\n586794\n4603\n6511\n170648.1\n121533\n\n\n1\nPS\nen\nMentally ill women -- Fiction,Feminist fiction...\nThe Yellow Wallpaper\nText\n26363\n1952\n2\nhttps://www.gutenberg.org/ebooks/1952\n1860\n...\n0.054174\n0.534787\n4.41\n15.0\n0.06\n26769\n102\n385\n7686.9\n6067\n\n\n2\nPZ,PR\nen\nFantasy\nAlice's Adventures in Wonderland\nText\n18882\n11\n3\nhttps://www.gutenberg.org/ebooks/11\n1832\n...\n0.041079\n0.497276\n4.65\n17.0\n0.06\n122719\n339\n1501\n33810.3\n26389\n\n\n3\nPR\nen\nMonsters -- Fiction;Frankenstein's monster (Fi...\nFrankenstein; Or, The Modern Prometheus\nText\n17128\n84\n4\nhttps://www.gutenberg.org/ebooks/84\n1797\n...\n0.100902\n0.539516\n4.77\n23.0\n0.04\n357604\n2604\n3239\n106802.1\n74959\n\n\n4\nPT\nen\nPsychological fiction,Metamorphosis -- Fiction\nMetamorphosis\nText\n15683\n5200\n5\nhttps://www.gutenberg.org/ebooks/5200\n1883\n...\n0.041997\n0.479019\n4.56\n27.0\n0.04\n100372\n397\n800\n28752.3\n22022\n\n\n\n\n5 rows × 38 columns\n\n\n\n\n# Checking Missing data\nmissing_data = df.isnull().sum()\n\nprint(missing_data)\n\nbibliography.congress classifications              159\nbibliography.languages                               0\nbibliography.subjects                              155\nbibliography.title                                   0\nbibliography.type                                    0\nmetadata.downloads                                   0\nmetadata.id                                          0\nmetadata.rank                                        0\nmetadata.url                                         0\nbibliography.author.birth                            0\nbibliography.author.death                            0\nbibliography.author.name                             0\nbibliography.publication.day                         0\nbibliography.publication.full                        0\nbibliography.publication.month                       0\nbibliography.publication.month name                  0\nbibliography.publication.year                        0\nmetadata.formats.total                               0\nmetadata.formats.types                               0\nmetrics.difficulty.automated readability index       0\nmetrics.difficulty.coleman liau index                0\nmetrics.difficulty.dale chall readability score      0\nmetrics.difficulty.difficult words                   0\nmetrics.difficulty.flesch kincaid grade              0\nmetrics.difficulty.flesch reading ease               0\nmetrics.difficulty.gunning fog                       0\nmetrics.difficulty.linsear write formula             0\nmetrics.difficulty.smog index                        0\nmetrics.sentiments.polarity                          0\nmetrics.sentiments.subjectivity                      0\nmetrics.statistics.average letter per word           0\nmetrics.statistics.average sentence length           0\nmetrics.statistics.average sentence per word         0\nmetrics.statistics.characters                        0\nmetrics.statistics.polysyllables                     0\nmetrics.statistics.sentences                         0\nmetrics.statistics.syllables                         0\nmetrics.statistics.words                             0\ndtype: int64\n\n\nWe observe 159 missing data in “bibliography.congress classifications” column and 155 in “bibliography.subjects” column. Since both variables are not the primary focus of this research, we don’t need to further investigate these missing data.  We also wonder how many authors are in this dataset?\n\nprint(\"There are\", len(df[\"bibliography.author.name\"].unique()), \"authors in classics.csv dataset.\")\n\nThere are 555 authors in classics.csv dataset.\n\n\n\n\n\n\n\n\n\n\n\nbibliography.congress classifications\nbibliography.languages\nbibliography.subjects\nbibliography.title\nbibliography.type\nmetadata.downloads\nmetadata.id\nmetadata.rank\nmetadata.url\nbibliography.author.birth\n...\nmetrics.sentiments.polarity\nmetrics.sentiments.subjectivity\nmetrics.statistics.average letter per word\nmetrics.statistics.average sentence length\nmetrics.statistics.average sentence per word\nmetrics.statistics.characters\nmetrics.statistics.polysyllables\nmetrics.statistics.sentences\nmetrics.statistics.syllables\nmetrics.statistics.words\n\n\n\n\n2\nPZ,PR\nen\nFantasy\nAlice's Adventures in Wonderland\nText\n18882\n11\n3\nhttps://www.gutenberg.org/ebooks/11\n1832\n...\n0.041079\n0.497276\n4.65\n17.0\n0.06\n122719\n339\n1501\n33810.3\n26389\n\n\n67\nPR,PZ\nen\nFantasy\nThrough the Looking-Glass\nText\n3626\n12\n68\nhttps://www.gutenberg.org/ebooks/12\n1832\n...\n0.087243\n0.486645\n4.71\n15.0\n0.07\n137377\n373\n1938\n37274.4\n29170\n\n\n183\nPZ,PR\nen\nFantasy\nAlice's Adventures in Wonderland\nText\n1660\n19033\n184\nhttps://www.gutenberg.org/ebooks/19033\n1832\n...\n0.030640\n0.470152\n4.66\n16.0\n0.06\n45325\n139\n592\n12559.5\n9721\n\n\n275\nPZ,PR\nen\nFantasy\nAlice's Adventures in Wonderland: Illustrated ...\nText\n1229\n28885\n276\nhttps://www.gutenberg.org/ebooks/28885\n1832\n...\n0.036749\n0.498011\n4.71\n17.0\n0.06\n128331\n384\n1551\n35064.9\n27270\n\n\n654\nPR,PZ\nde\nFantasy\nAlice's Abenteuer im Wunderland\nText\n599\n19778\n655\nhttps://www.gutenberg.org/ebooks/19778\n1832\n...\n0.414417\n0.538158\n5.39\n15.0\n0.06\n137490\n459\n1637\n34974.9\n25515\n\n\n733\nBC\nen\nLogic -- Juvenile literature;Logic, Symbolic a...\nThe Game of Logic\nText\n544\n4763\n734\nhttps://www.gutenberg.org/ebooks/4763\n1832\n...\n0.072815\n0.494916\n5.48\n13.0\n0.08\n78980\n430\n1088\n18483.3\n14408\n\n\n790\nBC\nen\nLogic, Symbolic and mathematical\nSymbolic Logic\nText\n510\n28696\n791\nhttps://www.gutenberg.org/ebooks/28696\n1832\n...\n0.076662\n0.466312\n5.59\n13.0\n0.07\n313684\n2063\n4045\n69408.0\n56160\n\n\n\n\n7 rows × 38 columns\n\n\n\nWe manually examine Lewis Caroll related dataframe since it only has 7 rows/items and there’s no missing values in this dataframe. We also notice there’s 4 versions of Alice’s Adventure in Wonderland and one of them is in Germany. To avoid repetitive analysis on the same book, here we only select “https://www.gutenberg.org/ebooks/11 Alice’s Adventure in Wonderland with the higest download. Subsetting this dataframe to the no-repeat (np) dataframe we need for our detail analysis:\n\ndf_CL_np = df_CL.iloc[[0,1, 5, 6]]\ndf_CL_np\n\n\n\n\n\n\n\n\nbibliography.congress classifications\nbibliography.languages\nbibliography.subjects\nbibliography.title\nbibliography.type\nmetadata.downloads\nmetadata.id\nmetadata.rank\nmetadata.url\nbibliography.author.birth\n...\nmetrics.sentiments.polarity\nmetrics.sentiments.subjectivity\nmetrics.statistics.average letter per word\nmetrics.statistics.average sentence length\nmetrics.statistics.average sentence per word\nmetrics.statistics.characters\nmetrics.statistics.polysyllables\nmetrics.statistics.sentences\nmetrics.statistics.syllables\nmetrics.statistics.words\n\n\n\n\n2\nPZ,PR\nen\nFantasy\nAlice's Adventures in Wonderland\nText\n18882\n11\n3\nhttps://www.gutenberg.org/ebooks/11\n1832\n...\n0.041079\n0.497276\n4.65\n17.0\n0.06\n122719\n339\n1501\n33810.3\n26389\n\n\n67\nPR,PZ\nen\nFantasy\nThrough the Looking-Glass\nText\n3626\n12\n68\nhttps://www.gutenberg.org/ebooks/12\n1832\n...\n0.087243\n0.486645\n4.71\n15.0\n0.07\n137377\n373\n1938\n37274.4\n29170\n\n\n733\nBC\nen\nLogic -- Juvenile literature;Logic, Symbolic a...\nThe Game of Logic\nText\n544\n4763\n734\nhttps://www.gutenberg.org/ebooks/4763\n1832\n...\n0.072815\n0.494916\n5.48\n13.0\n0.08\n78980\n430\n1088\n18483.3\n14408\n\n\n790\nBC\nen\nLogic, Symbolic and mathematical\nSymbolic Logic\nText\n510\n28696\n791\nhttps://www.gutenberg.org/ebooks/28696\n1832\n...\n0.076662\n0.466312\n5.59\n13.0\n0.07\n313684\n2063\n4045\n69408.0\n56160\n\n\n\n\n4 rows × 38 columns\n\n\n\nEach “Plain Text UTF-8” file is stored in its corresponding metadata.url with addtional suffix “/pg{metadata.id}.txt”. With this feature we can extract the plain text of these four books by their “metadata.url”. Append this to the above dataframe:\n\nmetadata_ids = df_CL_np[\"metadata.id\"]\nplaintext_urls = []\n\n# Build the plaintext URLs for each book using the metadata.ids\nfor metadata_id in metadata_ids:\n    plaintext_url = f\"https://www.gutenberg.org/cache/epub/{metadata_id}/pg{metadata_id}.txt\"\n    plaintext_urls.append(plaintext_url)\n    \n\n\n# load the text file into objects named by the book title:\nimport requests\n\nplaintext_urls\ntitles = df_CL_np[\"bibliography.title\"].tolist()\nbook_texts = {}\n \nfor title, url in zip(titles, plaintext_urls):\n    response = requests.get(url)\n    plain_text = response.text\n    book_texts[title] = plain_text\n\nalice = book_texts[\"Alice's Adventures in Wonderland\"]\nglass = book_texts[\"Through the Looking-Glass\"]\ngame = book_texts[\"The Game of Logic\"]\nsymbolic = book_texts[\"Symbolic Logic\"] \n\n\n\nWord Count for Alice: 29564\nWord Count for Glass: 32784\nWord Count for Game: 20504\nWord Count for Symbolic: 69243\n\n\nBy checking the word count for each book and comparing them to the word count in the df_CL_np dataframe, we know our texts are loaded successfully into these objects. These word counts are higher than ones in the df_CL_np dataframe; we haven’t precisely tokenized them by words.\n\n\n\nMy Analytical Process will be divided into two parts: first, the comparison between Lewis Caroll to the others in the big classics dataset; second, a detail investigation of the features of our selected books from Lewis Carroll.\nIn the first part, I will perform such comparisons by visualizing my selected variables for the classics dataset and highlighting the same variables in Lewis Carroll’s dataframe in their corresponding positions. Visualizations for this part will include histograms with highlighted lines, a scatter-plot with regression line and highlighted points."
  },
  {
    "objectID": "posts/Topics.html#iii.results-data-exploration-your-findings-and-your-visuals",
    "href": "posts/Topics.html#iii.results-data-exploration-your-findings-and-your-visuals",
    "title": "Lewis Carroll - Final Project Blog",
    "section": "",
    "text": "Now we move on to fit Lewis Caroll into the “big picture” of the large “classics.csv” dataset and compare him with the others through data analysis. In this process we will also conduct some exploratory data analysis just to learn more about the classic.csv dataset.\nGiven the popularity of Alice’s Adventure in Wonderland , Lewis Caroll is undoubtedly a well-known writer in the field of classical literature. But how popular is he compared to the other authors, measured by the number of available books in the GP project? With the following codes we will performe this analysis.\n\n\ncount    555.000000\nmean       1.812613\nstd        2.447467\nmin        1.000000\n25%        1.000000\n50%        1.000000\n75%        2.000000\nmax       34.000000\nName: bibliography.author.name, dtype: float64\nUnknown                    34\nShakespeare, William       19\nTwain, Mark                19\nDickens, Charles           18\nDoyle, Arthur Conan        14\n                           ..\nHerodotus                   1\nBurke, Edmund               1\nMachen, Arthur              1\nBoy Scouts of America       1\nMorse, Katharine Duncan     1\nName: bibliography.author.name, Length: 555, dtype: int64\n\n\n\n\nLewis Carroll's Rank: 17.0\n\n\n\n# Visualization1: Visualize Lewis Carroll's rank in the top 50 authors.\nimport matplotlib.pyplot as plt\n\n# Create a bar plot for the top 50 authors, including Lewis Carroll\ntop_authors = author_counts.head(50)\n\n# Sort the top authors Series by count in descending order\ntop_authors = top_authors.sort_values(ascending=False)\n\n# Create the bar plot\nplt.figure(figsize=(12, 6))  # Optional: Adjust the size of the plot\nax = top_authors.plot(kind='bar', color='skyblue')\n\n# Highlight Lewis Carroll's bar with a different color (e.g., red)\nlewis_carroll_index = top_authors.index.get_loc(\"Carroll, Lewis\")\nax.patches[lewis_carroll_index].set_facecolor('red')\n\n# Add labels and title\nplt.xlabel('Author')\nplt.ylabel('Number of Books')\nplt.title('V1.Number of Books per Author (Top 50)')\n\n# Display the plot\nplt.show()\n\n\n\n\nSince there are over 500 authors in the GP project and over 50% of them only have 1 book collected in the project, if we plot all of their book counts we expect to see a highly right-skewed, less insightful graph. Therefore, it’s better to tailor the graph to the top 50 writers and compare Lewis (rank 17) with the others.\nIn “Number of Books per Author (Top 50)”, Lewis is highlighted by the red color. Authors before him are also well-known writers like “Mark Twain,”Shakespeare”, “Oscar Wilde”, “Jane Austen” and etc.We should notice the genre of their works can be quite different: for example, “Mark Twain” like to write short novels and “Shakespear” writes lots of poems and dramas; these, given their short length, may increase their authors’ book count. We also notice many books fall into names of “Unknown” and “Anonymous”, which should be ignored from this graph since they’re not correctly defined. After these modifications, we can conclude Lewis Carroll is a very popular writer even among the top 50 writers in the GP project.\n\n\n\n\nNext, we want to perform an analysis on the sentiment analysis scores of Lewis and the others and research the relationship between sentiment subjectivity and sentiment polarity.We also want to know where Lewis sits in the big picture of the GPD project sentiment scores.\n\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\nx = df[\"metrics.sentiments.subjectivity\"]\ny = df[\"metrics.sentiments.polarity\"]\n\nx_lewis = df_CL_np[\"metrics.sentiments.subjectivity\"]\ny_lewis = df_CL_np[\"metrics.sentiments.polarity\"]\n\n# Create a scatter plot for the others\nplt.scatter(x, y, label = \"others\")\n# Create a scatter plot for lewis\nplt.scatter(x_lewis, y_lewis, label = \"Lewis\")\n\n# Add labels and title\nplt.xlabel('Subjectivity')\nplt.ylabel('Polarity')\nplt.title('V2. Correlation between Subjectivity and Polarity ')\n\n# fit regression for the others\nlm = LinearRegression()\nx = np.array(x).reshape(-1, 1)\ny = np.array(y).reshape(-1, 1)\nlm.fit(x,y )\n# Get the coefficients of the linear model for the others\nslope = lm.coef_[0]\nintercept = lm.intercept_\nplt.plot(x, slope * x + intercept, color='red', label='Regression Line')\n\n\n# Show the plot\nplt.show()\n\nprint(\"The slope of this graph is \",slope)\n\n\n\n\nThe slope of this graph is  [0.49959358]\n\n\nAs CORGIS database describes, “Subjectivity (as opposed to Objectivity) in particular refers to whether the text is opinionated or attempts to stay factual” and “Polarity in particular refers to how positive or negative the author is towards the content”. Through plotting them in the same scatter plot, we attempt to find if the more subjective an author is in his/her writing, the more positive will the overall attitude of the book be. \nIn this graph, we identify a positive relation between the sentiment subjectivity and sentiment polarity with a slope of 0.4995. We infer there’s a possibility that the more subjective an author is, the more positive this will be in his attitude towards his works.\nWe also view the majority of data points concentrated within the 0.4-06 subjectivity range for x-axis and the 0.0-0.2 polarity range for y-axis. Lewis Caroll locates in the center of this cluster, indicating he has an overall subjective tone and a positive choice of words in his writings.\n\n\n\n\nWhat about Lewis’ average sentence length compared to the other writers? Does he prefer to write in short or long sentences? This is also an important factor that influences one’s writing style. From our experience, we can tell that generally short sentences provide better readability while the long sentences require the reader to be more concentrated and skillful in reading. So does Lewis try to better engage his audience with shorter sentences or make his works more readible?\n\n\n2      17.0\n67     15.0\n733    13.0\n790    13.0\nName: metrics.statistics.average sentence length, dtype: float64\ncount    1006.000000\nmean       20.801193\nstd        10.740644\nmin         5.000000\n25%        15.000000\n50%        19.000000\n75%        24.000000\nmax       235.000000\nName: metrics.statistics.average sentence length, dtype: float64\n\n\nWe extract the average sentence length for four unique books in our Lewis Carroll dataframe. Then we add a five number description to the big classics dataframe on its average sentence length variable. We also visualize Lewis’ average sentence length together with the others’:\n\ndt_sentence_length = df['metrics.statistics.average sentence length']\ncl_sentence_length = df_CL_np[\"metrics.statistics.average sentence length\"]\n\nplt.hist(dt_sentence_length[dt_sentence_length &lt;40], bins = len(dt_sentence_length) ,edgecolor='black')\n\n# Add labels and title\nplt.xlabel('Average sentence length')\nplt.ylabel('Frequency')\nplt.title('V3: Average sentence length')\n\n# Display the histogram\nfor length in cl_sentence_length:\n    plt.axvline(length, color='red', linestyle='dashed', linewidth=1, label=f'Length = {length}')\n\n# Display the histogram\nplt.legend()\nplt.show()\n\n\n\n\nIn this graph, we observe 16 words/sentences is the most popular length for authors in the GP project. The graph is relatively right-skewed, meaning most writers prefer short-medium average sentence length in the first to the third quantile. Lewis’ books have shorter average sentences length than the average (mean = 20.801), all falling in between 0% to 50%. This might indicate Lewis prefers to write shorter sentence structure to engage his reader better.\n\n\n\n\nTo confirm our findings in our 3rd visualization, in the final step of our data analysis of comparing Lewis to the entire Classics dataframe, we will visualize the “metrics.difficulty.automated readability index” for all the books in GP project and highlight Lewis Caroll’s readability indexs with red color.\n\ndata = df[\"metrics.difficulty.automated readability index\"]\ndata_lewis = df_CL_np[\"metrics.difficulty.automated readability index\"]\n\n# Create a figure with two subplots\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n\n# Plot the histogram of the unfiltered data in the first subplot\nax1.hist(data, bins=len(data.unique()), edgecolor='black')\nax1.set_xlabel('Value')\nax1.set_ylabel('Frequency')\nax1.set_title('Histogram (All Data)')\n\n# Filter the data between 0 and 100\ndata_filtered = data[(data &gt;= 0) & (data &lt;= 40)]\n\n# Plot the histogram of the filtered data in the second subplot\nax2.hist(data_filtered, bins=len(data_filtered.unique()), edgecolor='blue')\nax2.set_xlabel('Value')\nax2.set_ylabel('Frequency')\nax2.set_title('V4.Histogram (Data between 0 and 40)')\n\n# Plot Lewis Carroll's data on the second subplot\nax2.hist(data_lewis, bins=len(data_lewis.unique()), color='red', alpha=0.6, edgecolor='black')\nax2.legend(['All Data',  'Lewis Carroll'])\n\n# Adjust layout to avoid overlapping labels\nplt.tight_layout()\n\n# Display the histograms\nplt.show()\n\nprint (\"readability index of Lewis Carroll \",data_lewis)\n\n\n\n\nreadability index of Lewis Carroll  2       9.3\n67      8.3\n733    11.0\n790    11.8\nName: metrics.difficulty.automated readability index, dtype: float64\n\n\nSince we observe the untailored plot has an outlier (&gt;120) that stretches the whole graph to the right and reduces the interpretability of our visualization, we decide to tailor the data between 0 and 40 since the vast majority of data fall into this range. \nBased on CORGIS database’ description, “The Automated Readability Index is a number indicating the understandability of the text. This number is an approximate US Grade Level needed to comprehend the text, calculated using the characters per word and words per sentences.” For example, if a book has 11 as its readability index, this means it’s readable for an 11th grader. \nAs said, we also highlight Lewis’ readability score in the second (the better) graph, by which we can see his readability indexes land on the lower side, which indicates his works are readable for young readers in middle/high school (7th grade- 12 grade).\n\n\n\n\n\n\n  To further process our data, we download necessary packages like nltk, matplotlib, requests. \n\n\nimport requests\nimport matplotlib.pyplot as plt\nimport nltk\n\nfrom nltk.tokenize import word_tokenize\nfrom nltk.sentiment import vader\nfrom nltk.corpus import stopwords\nfrom nltk.corpus import opinion_lexicon\nfrom nltk.stem.porter import PorterStemmer\n\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('vader_lexicon')\nnltk.download('opinion_lexicon')\n\n[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /home/jovyan/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n[nltk_data] Downloading package opinion_lexicon to\n[nltk_data]     /home/jovyan/nltk_data...\n[nltk_data]   Package opinion_lexicon is already up-to-date!\n\n\nTrue\n\n\nWe then extract the contents for our four selected books. We also import english stops as a python list from nltk.corpus package and analyzer from vader package for later use. Once we obtain string objects for each book, we tokenize each of them and remove stop words from them.\n\n\n\nAfter completing the above data processing steps, we are ready to create word clouds for each book. Through these word clouds, we can grasp the most frequently appeared words in each book and potentially their themes or subjects.\n\nfrom wordcloud import WordCloud\n\n# Assuming 'alice_words', 'glass_words', 'game_words', and 'symbolic_words' are the tokenized word lists.\n\ndef generate_word_cloud(book_title, word_list):\n    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(word_list))\n    plt.figure(figsize=(10, 5))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.title(f'Word Cloud for {book_title}')\n    plt.show()\n\n# Generate word clouds for each book\ngenerate_word_cloud(\"Alice's Adventures in Wonderland\", alice_words_nr)\ngenerate_word_cloud(\"Through the Looking-Glass\", glass_words_nr)\ngenerate_word_cloud(\"The Game of Logic\", game_words_nr)\ngenerate_word_cloud(\"Symbolic Logic\", symbolic_words_nr)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs we look through the word clouds for each graph, we do realize they are different by their subjects. The first two word clouds look similar with many identical words like “alice”, “thing”, “rabbit”, “door” because both books– Alice’s Adventure in Wonderland and Through the Looking-Glass–are storybook about the same protagonist Alice’s adventures.\nThe later two books all fall into the “Logic” subject. Therefore, we can see many similar terms about logic frequently appear in these two books, such as “x”, “syllogism”, “conclusion”, “proposition” and etc.\n\n\n\nAlthough word clouds reflect the most frequently appeared words in these books and disclose their themes to an extent, this technique still has its own limits, such as being too generalized and unable to describe the mood behind the words.\nTo complement the limits of a NLP technique, we usually use other NLP techniques to cover the areas it doesn’t explain. In my case, I’ll use sentiment analysis of positive and negative words to more precisely reflect Lewis Carroll’s writing style in Fantasy and Logic topics.\n\n#----------------------\n# Create horizontal bar plots\nplt.figure(figsize=(10, 6))\n# Plot for negative words\nplt.subplot(2, 2, 1)\nplt.barh(range(len(top_15_alice_ns_negative_words[::-1])), [count for word, count in top_15_alice_ns_negative_words[::-1]], align='center',color='purple')\nplt.yticks(range(len(top_15_alice_ns_negative_words[::-1])), [word for word, count in top_15_alice_ns_negative_words[::-1]])\nplt.xlabel('Frequency')\nplt.title('15 Most Common Negative Words in Alice')\n\n# Plot for positive words\nplt.subplot(2, 2, 2)\nplt.barh(range(len(top_15_alice_ns_positive_words[::-1])), [count for word, count in top_15_alice_ns_positive_words[::-1]], align='center',color='orange')\nplt.yticks(range(len(top_15_alice_ns_positive_words[::-1])), [word for word, count in top_15_alice_ns_positive_words[::-1]])\nplt.xlabel('Frequency')\nplt.title('15 Most Common Positive Words in Alice')\n\n# Plot for negative words\nplt.subplot(2, 2, 3)\nplt.barh(range(len(top_15_glass_ns_negative_words[::-1])), [count for word, count in top_15_glass_ns_negative_words[::-1]], align='center',color='purple')\nplt.yticks(range(len(top_15_glass_ns_negative_words[::-1])), [word for word, count in top_15_glass_ns_negative_words[::-1]])\nplt.xlabel('Frequency')\nplt.title('15 Most Common Negative Words in glass')\n\n# Plot for positive words\nplt.subplot(2, 2, 4)\nplt.barh(range(len(top_15_glass_ns_positive_words[::-1])), [count for word, count in top_15_glass_ns_positive_words[::-1]], align='center',color='orange')\nplt.yticks(range(len(top_15_glass_ns_positive_words[::-1])), [word for word, count in top_15_glass_ns_positive_words[::-1]])\nplt.xlabel('Frequency')\nplt.title('15 Most Common Positive Words in glass')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nAs we compare the 15 most frequently used positive words in Lewis’ two fantasy books Alie’s Adventure in Wonderland and Through the Looking-Glass, we find Lewis’ uses of positive words in his fantasy writing are very similar and have many overlaps across books. Words such as “like”, “well”, “great”,“good”, “wish” all ranked high in these lists.\nLooking into the 15 most frequently used negative words, we find although there are some overlapping words like “lying” and “poor”, the overall feeling is way more different than the homogeneousness we sense from the positive word lists. Based on this we can infer Lewis may set different challenges for Alice across two books with different use of negative words.\n \n\n\n\n#----------------------\n# Create horizontal bar plots\nplt.figure(figsize=(10, 6))\n\n# Plot for negative words\nplt.subplot(2, 2, 1)\nplt.barh(range(len(top_15_symbolic_ns_negative_words[::-1])), [count for word, count in top_15_symbolic_ns_negative_words[::-1]], align='center',color='purple')\nplt.yticks(range(len(top_15_symbolic_ns_negative_words[::-1])), [word for word, count in top_15_symbolic_ns_negative_words[::-1]])\nplt.xlabel('Frequency')\nplt.title('15 Most Common Negative Words in symbolic')\n\n# Plot for positive words\nplt.subplot(2, 2, 2)\nplt.barh(range(len(top_15_symbolic_ns_positive_words[::-1])), [count for word, count in top_15_symbolic_ns_positive_words[::-1]], align='center',color='orange')\nplt.yticks(range(len(top_15_symbolic_ns_positive_words[::-1])), [word for word, count in top_15_symbolic_ns_positive_words[::-1]])\nplt.xlabel('Frequency')\nplt.title('15 Most Common Positive Words in symbolic')\n\n# Plot for negative words\nplt.subplot(2, 2, 3)\nplt.barh(range(len(top_15_game_ns_negative_words[::-1])), [count for word, count in top_15_game_ns_negative_words[::-1]], align='center',color='purple')\nplt.yticks(range(len(top_15_game_ns_negative_words[::-1])), [word for word, count in top_15_game_ns_negative_words[::-1]])\nplt.xlabel('Frequency')\nplt.title('15 Most Common Negative Words in game')\n\n# Plot for positive words\nplt.subplot(2, 2, 4)\nplt.barh(range(len(top_15_game_ns_positive_words[::-1])), [count for word, count in top_15_game_ns_positive_words[::-1]], align='center',color='orange')\nplt.yticks(range(len(top_15_game_ns_positive_words[::-1])), [word for word, count in top_15_game_ns_positive_words[::-1]])\nplt.xlabel('Frequency')\nplt.title('15 Most Common Positive Words in game')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nRegarding Lewis Logic book writing, we found similar patterns exist in his fantasy books. Lewis prefers to use positive words from the same group to express an uplifting tone, while he uses different negative words to accurately describe different qualities or negations.\n\n\n\n\n# Split Alice's Adventure in Wonderland by chapters.\nimport re\n# Define the regular expression pattern to match chapter headings\nalice_chapter_pattern = r\"\\bCHAPTER\\b\"\n\n# Split the text into chapters based on the pattern\nalice_chapters = re.split(alice_chapter_pattern, alice, flags=re.IGNORECASE)\n\n# remove the first 1 (content before table of content)+12 (table of content)\nalice_chapters = alice_chapters[13:]\n\n# Initialize lists to store chapter numbers and sentiment scores\nalice_chapter_numbers = []\nalice_sentiment_scores = []\n\n# Iterate over the chapters in Alice's Adventures in Wonderland\nfor i, chapter_text in enumerate(alice_chapters, 1):\n    # Tokenize the chapter's text into words\n    words = nltk.word_tokenize(chapter_text)\n    \n    # Calculate the total chapter sentiment score by summing the compound scores of all the words in that chapter\n    chapter_score = sum(analyzer.polarity_scores(word)[\"compound\"] for word in words)\n    \n    # Append chapter number and sentiment score to the respective lists\n    alice_chapter_numbers.append(i)\n    alice_sentiment_scores.append(chapter_score)\n\n\n\n12\n12\n\n\n\n\n12\n12\n\n\n\n\n4\n4\n\n\n\n\n62\n62\n\n\n\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\n\n\n[9.590500000000002, 6.304400000000002, 9.064600000000008, 13.2118, 3.5087000000000024, 5.3100000000000005, 4.941000000000002, 6.0459, -3.1251999999999955, 10.476700000000001, 2.5824000000000016, 2.535399999999999, 12.669600000000008, 17.681499999999996, 20.522800000000004, 13.699000000000021, 23.6025, 32.70139999999999, 12.393300000000007, 24.61990000000001, 11.689600000000004, -0.5766, 0.0, 9.765900000000004, 10.095300000000112, -10.526699999999993, -18.835899999999967, 8.473900000000004, 0.0, -0.1531, -3.0889, 1.2140000000000002, 6.385199999999999, 0.0, 0.0, 0.0, 0.0, 0.0, -0.296, 0.0, -0.296, 0.2732, 0.0516, -2.9827999999999997, 0.0, 0.0, -0.8879999999999999, 0.0516, 0.0, 0.0, -0.4019, 0.0, -0.8879999999999999, 0.9981, -0.3818, -0.0837, 0.0, 0.0, 0.5337000000000001, -0.296, 2.0790000000000006, 1.7135, 1.3765999999999998, 2.9975, 1.3971, 2.4674000000000014, 5.6193, 0.5464, 0.4012, 4.4626, 0.0, 2.2735000000000003, -23.96019999999997, -0.12869999999999998, -0.5753999999999997, 0.2732, 1.9924, -8.778200000000002, -8.433900000000001, -0.6636999999999997, 1.4478, 9.459699999999994, -0.546, -4.054899999999999, 19.71710000000001, 0.6137999999999998, 3.609600000000003, -35.16309999999992, -24.156999999999957, 72.5355]\n\n\n\n# Set colors for positive, negative, and neutral scores\n\ncolors = ['purple' if score &lt; 0 else 'orange' if score &gt; 0 else 'blue' for score in combined_list]\nbar_width = 0.5\n\n# Create a 2x2 grid of subplots\nfig, axes = plt.subplots(2, 2, figsize=(15, 10))\n\n# Plot the first subplot for \"Alice's Adventure in Wonderland\"\naxes[0, 0].bar(alice_chapter_numbers, alice_sentiment_scores, color=colors, width=bar_width)\naxes[0, 0].set_xlabel(\"Scene Number\")\naxes[0, 0].set_ylabel(\"Sentiment Score\")\naxes[0, 0].set_title(\"Alice's Adventure in Wonderland\")\n\n# Plot the second subplot for \"Through the Looking Glass\"\naxes[0, 1].bar(glass_chapter_numbers, glass_sentiment_scores, color=colors, width=bar_width)\naxes[0, 1].set_xlabel(\"Scene Number\")\naxes[0, 1].set_ylabel(\"Sentiment Score\")\naxes[0, 1].set_title(\"Through the Looking Glass\")\n\n# Plot the third subplot for \"game\"\naxes[1, 0].bar(game_chapter_numbers, game_sentiment_scores, color=colors, width=bar_width)\naxes[1, 0].set_xlabel(\"Scene Number\")\naxes[1, 0].set_ylabel(\"Sentiment Score\")\naxes[1, 0].set_title(\"game\")\n\n# Plot the fourth subplot for \"symbolic\"\naxes[1, 1].bar(symbolic_chapter_numbers, symbolic_sentiment_scores, color=colors, width=bar_width)\naxes[1, 1].set_xlabel(\"Scene Number\")\naxes[1, 1].set_ylabel(\"Sentiment Score\")\naxes[1, 1].set_title(\"symbolic\")\n\n# Adjust layout and display the plots\nplt.tight_layout()\nplt.show()\n\n\n\n\nAs we visualize the polarity scores of Lewis’ four books, we identify he always hold a positive tone in his fantasy books but write more objectively (close to 0 score) or uses strong negations in his logic books. My assumption is in the logic book, since negations or counter examples are freuqently use as parts of the proof, it results an overall lower sentiment score for this type of books."
  },
  {
    "objectID": "posts/Topics.html#discussion",
    "href": "posts/Topics.html#discussion",
    "title": "Lewis Carroll - Final Project Blog",
    "section": "",
    "text": "what does your analysis show, what is the big picture, and how are these findings useful?\nBased on the above analysis, I’m able to conclude some uniqueness of Lewis Caroll few features I discover his writing style: 1. Lewis Caroll is a very popular (ranked as 17th) writer over 555 writers collected in the GP project. 2. He tends to be subjective in his writing with an overall positive attitude. 3. He prefers to write in short sentences, lower than the overall average sentence length in the GP project. 4. His works are usually easy to read, even for the 7th-12th grader. 5. Given he’s both a Mathematician and a fantasy writer, to create engaging works in both fields for different types of readers, Lewis approaches his writings with different tones. For his fantasy writings, he tends to use many positive words and holds a constant positive tone throughout the books. But for his logic books, he tends to be more critical and objective by using more negative or neutral words. 6. His choices of positive words are very similar across his fantasy books while the negative words are different to represent the varying adventure his protagonist–Alice–experiences. Similar patent is found in his logic writings: similar choices of positive words, different negative words to express varying negations and qualities.\nThese findings are useful for us to better understand Lewis Carroll’s writing style and are presentable for educational purposes. I think they will be very helpful literature teachers who want to incorporate Digital Humanity methods into his/her lecture and introduce Lewis Carroll from a computational angle. For Lewis’ reader, these findings are also useful as you can examine them in your reading of Lewis’ works and make comparisons. Although some of them are proved to be not true, in your process of validation–finding the right features about Lewis from the text–you still learn more than reading his texts passively. I think these are the benefits offered by my findings."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]